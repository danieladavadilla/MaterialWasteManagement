{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieladavadilla/MaterialWasteManagement/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EqKGRX7hcLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81e4a7b-dc0e-44d5-ea4a-c77fe16ece07"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqqC-i67jU8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b93720-3186-427f-ee13-f97152523823"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55BlWgJpiu3E"
      },
      "source": [
        "\"\"\"Headers\"\"\"\n",
        "import os\n",
        "import os.path as osp\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2djZNjG7tTa5"
      },
      "source": [
        "import os.path as osp\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "import math\n",
        "\n",
        "from skimage.transform import resize\n",
        "import scipy\n",
        "\n",
        "\n",
        "np.random.seed(111)\n",
        "torch.cuda.manual_seed_all(111)\n",
        "torch.manual_seed(111)\n",
        "\n",
        "\n",
        "class Dataset_Gary(Dataset):\n",
        "\n",
        "\tdef __init__(self, root, fold=\"train\",\n",
        "\t\t\t\t transform=None, target_transform=None):\n",
        "\t\t\n",
        "\t\tfold = fold.lower()\n",
        "\n",
        "\t\tself.train = False\n",
        "\t\tself.test = False\n",
        "\t\tself.val = False\n",
        "\n",
        "\t\tif fold == \"train\":\n",
        "\t\t\tself.train = True\n",
        "\t\telif fold == \"test\":\n",
        "\t\t\tself.test = True\n",
        "\t\telif fold == \"val\":\n",
        "\t\t\tself.val = True\n",
        "\t\telse:\n",
        "\t\t\traise RuntimeError(\"Not train-val-test\")\n",
        "\n",
        "\n",
        "\t\tself.root = os.path.expanduser(root)\n",
        "\t\tself.transform = transform\n",
        "\t\tself.target_transform = target_transform\n",
        "\n",
        "\t\tfpath = self.root\n",
        "\n",
        "\t\t# now load the picked numpy arrays\n",
        "\t\tself.data = []\n",
        "\t\tif self.train:\n",
        "\t\t\tself.datalist_dir = os.path.join(self.root, 'train_list.txt')\n",
        "\t\tif self.val:\n",
        "\t\t\tself.datalist_dir = os.path.join(self.root, 'val_list.txt')\n",
        "\t\tif self.test:\n",
        "\t\t\tself.datalist_dir = os.path.join(self.root, 'test_list.txt')\n",
        "\n",
        "\t\twith open(self.datalist_dir, 'r') as f:\n",
        "\t\t\tfor line in f:\n",
        "\t\t\t\tif line[0] == '#' or len(line.strip()) == 0:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tparams = line.strip().split()\n",
        "\t\t\t\tself.data.append({\n",
        "\t\t\t\t\t'file_name' : params[0],\n",
        "\t\t\t\t\t'label' : params[1],})\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tlabel = self.data[index]['label']\n",
        "\t\tif label == 'cardboard':\n",
        "\t\t\ttarget = 0\n",
        "\t\tif label == 'glass':\n",
        "\t\t\ttarget = 1\n",
        "\t\tif label == 'metal':\n",
        "\t\t\ttarget = 2\n",
        "\t\tif label == 'paper':\n",
        "\t\t\ttarget = 3\n",
        "\t\tif label == 'plastic':\n",
        "\t\t\ttarget = 4\n",
        "\t\tif label == 'trash':\n",
        "\t\t\ttarget = 5\n",
        "\t\timg = plt.imread(osp.join(self.root, self.data[index]['label'], self.data[index]['file_name']))\n",
        "\n",
        "\t\t# doing this so that it is consistent with all other datasets\n",
        "\t\t# to return a PIL Image\n",
        "\t\timg = Image.fromarray(img)\n",
        "\n",
        "\t\tif self.transform is not None:\n",
        "\t\t\timg = self.transform(img)\n",
        "\n",
        "\t\tif self.target_transform is not None:\n",
        "\t\t\ttarget = self.target_transform(target)\n",
        "\n",
        "\t\treturn img, target\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdo6AkH0maX"
      },
      "source": [
        "class PreTrainedResNet(nn.Module):\n",
        "  def __init__(self, num_classes, feature_extracting):\n",
        "    super(PreTrainedResNet, self).__init__()\n",
        "    \n",
        "    self.resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "    if feature_extracting:\n",
        "      for param in self.resnet18.parameters():\n",
        "          param.requires_grad = False\n",
        "    \n",
        "    num_feats = self.resnet18.fc.in_features\n",
        "    \n",
        "    self.resnet18.fc =  nn.Linear(num_feats,num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.resnet18.forward(x)\n",
        "    return x\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujUNEVsEvWwv"
      },
      "source": [
        "def train(model, optimizer, criterion, epoch, num_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  epoch_acc = 0.0\n",
        "  \n",
        "  for batch_idx, (images, labels) in enumerate(dataloaders['train']):\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    \n",
        "    outputs = model.forward(images)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += torch.sum(preds == labels).item()\n",
        "    \n",
        "  epoch_loss /= dataset_sizes['train']\n",
        "  epoch_acc /= dataset_sizes['train']\n",
        "  \n",
        "  print('TRAINING Epoch %d/%d Loss %.4f Accuracy %.4f' % (epoch, num_epochs, epoch_loss, epoch_acc))\n",
        "\n",
        "  return epoch_loss, epoch_acc\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md7WhEJ_1XGS"
      },
      "source": [
        "import sklearn.metrics as metric\n",
        "\n",
        "def test(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  f1_score = 0.0\n",
        "  f1_score_w = 0.0\n",
        "  conf_mat = np.zeros([len(class_names),len(class_names)])\n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        outputs = model.forward(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        predlabels = preds.cpu().numpy()\n",
        "        labels_num = labels.cpu().numpy()\n",
        "        for ind,label in enumerate(labels_num):\n",
        "          conf_mat[label,predlabels[ind]] = conf_mat[label,predlabels[ind]] + 1\n",
        "        \n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "          \n",
        "        f1_score += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='weighted', zero_division='warn')\n",
        "        f1_score_w += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='macro', zero_division='warn')\n",
        "\n",
        "    test_loss /= (dataset_sizes['test']*repeats)\n",
        "    test_acc /= (dataset_sizes['test']*repeats)\n",
        "    f1_score /= (dataset_sizes['test']*repeats)\n",
        "\n",
        "\n",
        "    print('Test Loss: %.4f Test Accuracy %.4f Weighted: %.4f Macro: %.4f' % (test_loss, test_acc, f1_score, f1_score_w))\n",
        "    return test_loss, test_acc, conf_mat\n",
        "\n",
        "\n",
        "def val(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(dataloaders['val']):\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "\n",
        "    test_loss /= (dataset_sizes['val']*repeats)\n",
        "    test_acc /= (dataset_sizes['val']*repeats)\n",
        "\n",
        "    print('Val Loss: %.4f Val Accuracy %.4f' % (test_loss, test_acc))\n",
        "\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsmSIWL8ovUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "a197ae54-18b1-4a17-b541-8bceb8bfa081"
      },
      "source": [
        "\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 0.001 \n",
        "BATCH_SIZE = 10\n",
        "RESNET_LAST_ONLY = False #Fine tunes only the last layer. Set to False to fine tune entire network\n",
        "\n",
        "root_path = 'dataset/'\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(384),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(384),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# loading datasets with PyTorch ImageFolder\n",
        "image_datasets_train = Dataset_Gary(root_path, fold=\"train\",\n",
        "\t\t\t\t transform=data_transforms['train'], target_transform=None)\n",
        "\n",
        "image_datasets_val = Dataset_Gary(root_path, fold=\"val\",\n",
        "\t\t\t\t transform=data_transforms['test'], target_transform=None)\n",
        "\n",
        "image_datasets_test = Dataset_Gary(root_path, fold=\"test\",\n",
        "\t\t\t\t transform=data_transforms['test'], target_transform=None)\n",
        "\n",
        "# defining data loaders to load data using image_datasets and transforms, here we also specify batch size for the mini batch\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(image_datasets_train, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "            \n",
        "dataloader_val = torch.utils.data.DataLoader(image_datasets_val, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "dataloaders = {'train': dataloader_train, 'test': dataloader_test, 'val':dataloader_val}\n",
        "\n",
        "dataset_size_train = len(image_datasets_train)\n",
        "dataset_size_val = len(image_datasets_val)\n",
        "dataset_size_test = len(image_datasets_test)\n",
        "\n",
        "dataset_sizes = {'train': dataset_size_train, 'test': dataset_size_test, 'val':dataset_size_val}\n",
        "\n",
        "class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "#Initialize the model\n",
        "model = PreTrainedResNet(len(class_names), RESNET_LAST_ONLY)\n",
        "model = model.cuda()\n",
        "\n",
        "#Setting the optimizer and loss criterion\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9 , weight_decay=1e-3)\n",
        "\n",
        "weightlist = [1,1,1,1,1,4]\n",
        "weightlist = torch.Tensor(weightlist)\n",
        "weightlist = weightlist.cuda()\n",
        "criterion = nn.CrossEntropyLoss(weight = weightlist)\n",
        "\n",
        "train_loss_list =[]\n",
        "train_acc_list = []\n",
        "val_loss_list =[]\n",
        "val_acc_list = []\n",
        "\n",
        "#Begin Train\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  t1,t2 = train(model, optimizer, criterion, epoch+1, NUM_EPOCHS)\n",
        "  train_loss_list.append(t1)\n",
        "  train_acc_list.append(t2)\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    t1,t2 = val(model, criterion)\n",
        "    val_loss_list.append(t1)\n",
        "    val_acc_list.append(t2)\n",
        "  \n",
        "print(\"Finished Training\")\n",
        "print(\"-\"*10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fb3317235c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# loading datasets with PyTorch ImageFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m image_datasets_train = Dataset_Gary(root_path, fold=\"train\",\n\u001b[0;32m---> 26\u001b[0;31m \t\t\t\t transform=data_transforms['train'], target_transform=None)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m image_datasets_val = Dataset_Gary(root_path, fold=\"val\",\n",
            "\u001b[0;32m<ipython-input-4-f9af6912e9c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fold, transform, target_transform)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalist_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_list.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalist_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/train_list.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip file.zip"
      ],
      "metadata": {
        "id": "oHytjc7WVOva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv9IOqoXozir"
      },
      "source": [
        "t1,t2,conf_mat = test(model, criterion)\n",
        "print('Conf Mat\\n',conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rji12O1KTumN"
      },
      "source": [
        "for i in range(6):\n",
        "  conf_mat[i,:] = conf_mat[i,:]/sum(conf_mat[i,:])\n",
        "\n",
        "plt.imshow(conf_mat, cmap='hot')\n",
        "\n",
        "plt.xticks([0,1,2,3,4,5],class_names)\n",
        "plt.yticks([0,1,2,3,4,5],class_names)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd_lkTdoUaOX"
      },
      "source": [
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(1)  # pause a bit so that plots are updated\n",
        "    \n",
        "def visualize_model(model, num_images=8):\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "       \n",
        "\n",
        "        for j in range(images.size()[0]):\n",
        "            # if preds[j] == labels[j]:\n",
        "            #   continue \n",
        "            images_so_far += 1\n",
        "            #ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "  \n",
        "            #plt.axis('off')\n",
        "            #ax.set_title('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "            print('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "            imshow(images.cpu().data[j])\n",
        "\n",
        "            if images_so_far == num_images:\n",
        "              return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUYa3X4ZrCqk"
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irbulScrVkRi"
      },
      "source": [
        "from scipy import interpolate\n",
        "x = np.arange(5, 25)\n",
        "x_train = np.arange(0,25)\n",
        "x1 = [5, 10, 15, 20, 25]\n",
        "f_loss = interpolate.interp1d(x1, val_loss_list)\n",
        "f_accuracy = interpolate.interp1d(x1, val_acc_list)\n",
        "\n",
        "\n",
        "val_acc = f_accuracy(x)   # use interpolation function returned by `interp1d`\n",
        "val_loss = f_loss(x)\n",
        "\n",
        "train_loss_list\n",
        "train_acc_list\n",
        "val_loss\n",
        "val_acc\n",
        "\n",
        "\n",
        "plt.plot(x_train, train_loss_list)\n",
        "plt.plot(x, val_loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(x_train, train_acc_list)\n",
        "plt.plot(x, val_acc)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyDPGRCgtfth"
      },
      "source": [
        "# def test_new(dataloader_new, model, criterion, repeats=2):\n",
        "#   model.eval()\n",
        "  \n",
        "#   test_loss = 0.0\n",
        "#   test_acc = 0.0\n",
        "#   f1_score = 0.0\n",
        "#   f1_score_w = 0.0\n",
        "#   conf_mat = np.zeros([len(class_names),len(class_names)])\n",
        "#   with torch.no_grad():\n",
        "#     for itr in range(repeats):\n",
        "#       for batch_idx, (images, labels) in enumerate(dataloader_new):\n",
        "#         #move to GPU\n",
        "#         images, labels = images.cuda(), labels.cuda()\n",
        "#         #print(images.shape())\n",
        "\n",
        "#         #forward\n",
        "#         outputs = model.forward(images)\n",
        "#         _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "#         predlabels = preds.cpu().numpy()\n",
        "#         labels_num = labels.cpu().numpy()\n",
        "#         for ind,label in enumerate(labels_num):\n",
        "#           conf_mat[label,predlabels[ind]] = conf_mat[label,predlabels[ind]] + 1\n",
        "        \n",
        "\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "#         test_loss += loss.item()\n",
        "#         test_acc += torch.sum(preds == labels).item()\n",
        "          \n",
        "#         f1_score += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='weighted', zero_division='warn')\n",
        "#         f1_score_w += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='macro', zero_division='warn')\n",
        "\n",
        "#     test_loss /= (dataset_sizes['test']*repeats)\n",
        "#     test_acc /= (dataset_sizes['test']*repeats)\n",
        "#     f1_score /= (dataset_sizes['test']*repeats)\n",
        "\n",
        "\n",
        "#     print('Test Loss: %.4f Test Accuracy %.4f Weighted: %.4f Macro: %.4f' % (test_loss, test_acc, f1_score, f1_score_w))\n",
        "#     return test_loss, test_acc, conf_mat\n",
        "\n",
        "# root_path_new = 'our_dataset/' #If your data is in a different folder, set the path accodordingly\n",
        "\n",
        "# new_dataset_test = Dataset_Gary(root_path_new, fold=\"test\",\n",
        "# \t\t\t\t transform=transforms.Compose([\n",
        "#         transforms.Resize((384, 512)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#     ]), target_transform=None)\n",
        "\n",
        "# # defining data loaders to load data using image_datasets and transforms, here we also specify batch size for the mini batch\n",
        "\n",
        "# dataloader_test_new = torch.utils.data.DataLoader(new_dataset_test, batch_size=BATCH_SIZE,\n",
        "#                                              shuffle=True, num_workers=4)\n",
        "\n",
        "# dataloaders = {'train': dataloader_train, 'test': dataloader_test_new, 'val':dataloader_val}\n",
        "\n",
        "# dataset_size_train = len(image_datasets_train)\n",
        "# dataset_size_val = len(image_datasets_val)\n",
        "# dataset_size_test_new = len(new_dataset_test)\n",
        "\n",
        "# dataset_sizes = {'train': dataset_size_train, 'test': dataset_size_test_new, 'val':dataset_size_val}\n",
        "\n",
        "# t1_new,t2_new,conf_mat_new = test_new(dataloader_test_new,model, criterion)\n",
        "# print('Conf Mat\\n',conf_mat_new)\n",
        "\n",
        "# def imshow(inp, title=None):\n",
        "#     \"\"\"Imshow for Tensor.\"\"\"\n",
        "#     inp = inp.numpy().transpose((1, 2, 0))\n",
        "#     inp = np.clip(inp, 0, 1)\n",
        "#     plt.axis(\"off\")\n",
        "#     plt.imshow(inp)\n",
        "#     if title is not None:\n",
        "#         plt.title(title)\n",
        "#     plt.pause(1)  # pause a bit so that plots are updated\n",
        "    \n",
        "# def visualize_model_new(dataloader, model, num_images=8):\n",
        "#     images_so_far = 0\n",
        "#     fig = plt.figure()\n",
        "\n",
        "#     for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "#         #move to GPU\n",
        "#         images, labels = images.cuda(), labels.cuda()\n",
        "        \n",
        "#         outputs = model(images)\n",
        "        \n",
        "#         _, preds = torch.max(outputs.data, 1)\n",
        "       \n",
        "\n",
        "#         for j in range(images.size()[0]):\n",
        "#             #if preds[j] == labels[j]:\n",
        "#              # continue \n",
        "#             images_so_far += 1\n",
        "#             #ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "  \n",
        "#             #plt.axis('off')\n",
        "#             #ax.set_title('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "#             print('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "#             imshow(images.cpu().data[j])\n",
        "\n",
        "#             if images_so_far ==20:\n",
        "#               return\n",
        "# visualize_model_new(dataloader_test_new,model)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}